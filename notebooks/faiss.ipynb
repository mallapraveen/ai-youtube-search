{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(90633, 7)"
      ]
     },
     "execution_count": 1,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import pandas as pd\n",
    "\n",
    "df =pd.read_csv('D:\\\\AI-youtube\\\\ai-youtube-search\\data_files\\\\videos_info\\\\playlist_info\\\\Dataset.csv')\n",
    "df.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0         Gonna start this stack quest with the silly s...\n",
       "1         Note, this stack quest was originally prepare...\n",
       "2         If you like silly songs, are you interested i...\n",
       "3         Why not why? If you don't like silly songs, a...\n",
       "4         Otherwise, you might not like Stack Quest. Wh...\n",
       "                               ...                        \n",
       "90628    already taken Sorry. I also by the way, also c...\n",
       "90629    It has a bunch of parts that are maybe not sup...\n",
       "90630    might be a bit tricky. And, but the rest and t...\n",
       "90631    happens, maybe there's a CNN, maybe the CNN fe...\n",
       "90632    give this thing a read, give this video a like...\n",
       "Name: text, Length: 90633, dtype: object"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df['text']\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Retrieving notices: ...working... done\n",
      "Collecting package metadata (current_repodata.json): ...working... done\n",
      "Solving environment: ...working... done\n",
      "\n",
      "# All requested packages already installed.\n",
      "\n",
      "\n",
      "Note: you may need to restart the kernel to use updated packages.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "==> WARNING: A newer version of conda exists. <==\n",
      "  current version: 23.3.0\n",
      "  latest version: 23.3.1\n",
      "\n",
      "Please update conda by running\n",
      "\n",
      "    $ conda update -n base -c defaults conda\n",
      "\n",
      "Or to minimize the number of packages updated during conda update use\n",
      "\n",
      "     conda install conda=23.3.1\n",
      "\n",
      "\n"
     ]
    }
   ],
   "source": [
    "conda install -c pytorch/label/nightly faiss-cpu"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "import faiss"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: ipywidgets in d:\\ai-youtube\\ai-youtube-search\\env\\lib\\site-packages (8.0.6)\n",
      "Requirement already satisfied: widgetsnbextension~=4.0.7 in d:\\ai-youtube\\ai-youtube-search\\env\\lib\\site-packages (from ipywidgets) (4.0.7)\n",
      "Requirement already satisfied: ipython>=6.1.0 in d:\\ai-youtube\\ai-youtube-search\\env\\lib\\site-packages (from ipywidgets) (8.12.0)\n",
      "Requirement already satisfied: jupyterlab-widgets~=3.0.7 in d:\\ai-youtube\\ai-youtube-search\\env\\lib\\site-packages (from ipywidgets) (3.0.7)\n",
      "Requirement already satisfied: ipykernel>=4.5.1 in d:\\ai-youtube\\ai-youtube-search\\env\\lib\\site-packages (from ipywidgets) (6.15.0)\n",
      "Requirement already satisfied: traitlets>=4.3.1 in d:\\ai-youtube\\ai-youtube-search\\env\\lib\\site-packages (from ipywidgets) (5.9.0)\n",
      "Requirement already satisfied: psutil in d:\\ai-youtube\\ai-youtube-search\\env\\lib\\site-packages (from ipykernel>=4.5.1->ipywidgets) (5.9.0)\n",
      "Requirement already satisfied: pyzmq>=17 in d:\\ai-youtube\\ai-youtube-search\\env\\lib\\site-packages (from ipykernel>=4.5.1->ipywidgets) (23.2.0)\n",
      "Requirement already satisfied: tornado>=6.1 in d:\\ai-youtube\\ai-youtube-search\\env\\lib\\site-packages (from ipykernel>=4.5.1->ipywidgets) (6.2)\n",
      "Requirement already satisfied: jupyter-client>=6.1.12 in d:\\ai-youtube\\ai-youtube-search\\env\\lib\\site-packages (from ipykernel>=4.5.1->ipywidgets) (8.2.0)\n",
      "Requirement already satisfied: matplotlib-inline>=0.1 in d:\\ai-youtube\\ai-youtube-search\\env\\lib\\site-packages (from ipykernel>=4.5.1->ipywidgets) (0.1.6)\n",
      "Requirement already satisfied: packaging in d:\\ai-youtube\\ai-youtube-search\\env\\lib\\site-packages (from ipykernel>=4.5.1->ipywidgets) (23.1)\n",
      "Requirement already satisfied: nest-asyncio in d:\\ai-youtube\\ai-youtube-search\\env\\lib\\site-packages (from ipykernel>=4.5.1->ipywidgets) (1.5.6)\n",
      "Requirement already satisfied: debugpy>=1.0 in d:\\ai-youtube\\ai-youtube-search\\env\\lib\\site-packages (from ipykernel>=4.5.1->ipywidgets) (1.5.1)\n",
      "Requirement already satisfied: pygments>=2.4.0 in d:\\ai-youtube\\ai-youtube-search\\env\\lib\\site-packages (from ipython>=6.1.0->ipywidgets) (2.15.1)\n",
      "Requirement already satisfied: pickleshare in d:\\ai-youtube\\ai-youtube-search\\env\\lib\\site-packages (from ipython>=6.1.0->ipywidgets) (0.7.5)\n",
      "Requirement already satisfied: stack-data in d:\\ai-youtube\\ai-youtube-search\\env\\lib\\site-packages (from ipython>=6.1.0->ipywidgets) (0.6.2)\n",
      "Requirement already satisfied: typing-extensions in d:\\ai-youtube\\ai-youtube-search\\env\\lib\\site-packages (from ipython>=6.1.0->ipywidgets) (4.5.0)\n",
      "Requirement already satisfied: prompt-toolkit!=3.0.37,<3.1.0,>=3.0.30 in d:\\ai-youtube\\ai-youtube-search\\env\\lib\\site-packages (from ipython>=6.1.0->ipywidgets) (3.0.38)\n",
      "Requirement already satisfied: jedi>=0.16 in d:\\ai-youtube\\ai-youtube-search\\env\\lib\\site-packages (from ipython>=6.1.0->ipywidgets) (0.18.2)\n",
      "Requirement already satisfied: decorator in d:\\ai-youtube\\ai-youtube-search\\env\\lib\\site-packages (from ipython>=6.1.0->ipywidgets) (5.1.1)\n",
      "Requirement already satisfied: backcall in d:\\ai-youtube\\ai-youtube-search\\env\\lib\\site-packages (from ipython>=6.1.0->ipywidgets) (0.2.0)\n",
      "Requirement already satisfied: colorama in d:\\ai-youtube\\ai-youtube-search\\env\\lib\\site-packages (from ipython>=6.1.0->ipywidgets) (0.4.6)\n",
      "Requirement already satisfied: parso<0.9.0,>=0.8.0 in d:\\ai-youtube\\ai-youtube-search\\env\\lib\\site-packages (from jedi>=0.16->ipython>=6.1.0->ipywidgets) (0.8.3)\n",
      "Requirement already satisfied: jupyter-core!=5.0.*,>=4.12 in d:\\ai-youtube\\ai-youtube-search\\env\\lib\\site-packages (from jupyter-client>=6.1.12->ipykernel>=4.5.1->ipywidgets) (5.3.0)\n",
      "Requirement already satisfied: importlib-metadata>=4.8.3 in d:\\ai-youtube\\ai-youtube-search\\env\\lib\\site-packages (from jupyter-client>=6.1.12->ipykernel>=4.5.1->ipywidgets) (6.5.0)\n",
      "Requirement already satisfied: python-dateutil>=2.8.2 in d:\\ai-youtube\\ai-youtube-search\\env\\lib\\site-packages (from jupyter-client>=6.1.12->ipykernel>=4.5.1->ipywidgets) (2.8.2)\n",
      "Requirement already satisfied: wcwidth in d:\\ai-youtube\\ai-youtube-search\\env\\lib\\site-packages (from prompt-toolkit!=3.0.37,<3.1.0,>=3.0.30->ipython>=6.1.0->ipywidgets) (0.2.6)\n",
      "Requirement already satisfied: executing>=1.2.0 in d:\\ai-youtube\\ai-youtube-search\\env\\lib\\site-packages (from stack-data->ipython>=6.1.0->ipywidgets) (1.2.0)\n",
      "Requirement already satisfied: pure-eval in d:\\ai-youtube\\ai-youtube-search\\env\\lib\\site-packages (from stack-data->ipython>=6.1.0->ipywidgets) (0.2.2)\n",
      "Requirement already satisfied: asttokens>=2.1.0 in d:\\ai-youtube\\ai-youtube-search\\env\\lib\\site-packages (from stack-data->ipython>=6.1.0->ipywidgets) (2.2.1)\n",
      "Requirement already satisfied: six in d:\\ai-youtube\\ai-youtube-search\\env\\lib\\site-packages (from asttokens>=2.1.0->stack-data->ipython>=6.1.0->ipywidgets) (1.16.0)\n",
      "Requirement already satisfied: zipp>=0.5 in d:\\ai-youtube\\ai-youtube-search\\env\\lib\\site-packages (from importlib-metadata>=4.8.3->jupyter-client>=6.1.12->ipykernel>=4.5.1->ipywidgets) (3.15.0)\n",
      "Requirement already satisfied: platformdirs>=2.5 in d:\\ai-youtube\\ai-youtube-search\\env\\lib\\site-packages (from jupyter-core!=5.0.*,>=4.12->jupyter-client>=6.1.12->ipykernel>=4.5.1->ipywidgets) (3.2.0)\n",
      "Requirement already satisfied: pywin32>=300 in d:\\ai-youtube\\ai-youtube-search\\env\\lib\\site-packages (from jupyter-core!=5.0.*,>=4.12->jupyter-client>=6.1.12->ipykernel>=4.5.1->ipywidgets) (305.1)\n",
      "Note: you may need to restart the kernel to use updated packages.\n"
     ]
    }
   ],
   "source": [
    "pip install ipywidgets"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: sentence-transformers in d:\\ai-youtube\\ai-youtube-search\\env\\lib\\site-packages (2.2.2)\n",
      "Requirement already satisfied: scikit-learn in d:\\ai-youtube\\ai-youtube-search\\env\\lib\\site-packages (from sentence-transformers) (1.2.2)\n",
      "Requirement already satisfied: sentencepiece in d:\\ai-youtube\\ai-youtube-search\\env\\lib\\site-packages (from sentence-transformers) (0.1.98)\n",
      "Requirement already satisfied: numpy in d:\\ai-youtube\\ai-youtube-search\\env\\lib\\site-packages (from sentence-transformers) (1.23.5)\n",
      "Requirement already satisfied: huggingface-hub>=0.4.0 in d:\\ai-youtube\\ai-youtube-search\\env\\lib\\site-packages (from sentence-transformers) (0.13.4)\n",
      "Requirement already satisfied: tqdm in d:\\ai-youtube\\ai-youtube-search\\env\\lib\\site-packages (from sentence-transformers) (4.65.0)\n",
      "Requirement already satisfied: scipy in d:\\ai-youtube\\ai-youtube-search\\env\\lib\\site-packages (from sentence-transformers) (1.10.1)\n",
      "Requirement already satisfied: nltk in d:\\ai-youtube\\ai-youtube-search\\env\\lib\\site-packages (from sentence-transformers) (3.8.1)\n",
      "Requirement already satisfied: torchvision in d:\\ai-youtube\\ai-youtube-search\\env\\lib\\site-packages (from sentence-transformers) (0.15.1)\n",
      "Requirement already satisfied: torch>=1.6.0 in d:\\ai-youtube\\ai-youtube-search\\env\\lib\\site-packages (from sentence-transformers) (2.0.0)\n",
      "Requirement already satisfied: transformers<5.0.0,>=4.6.0 in d:\\ai-youtube\\ai-youtube-search\\env\\lib\\site-packages (from sentence-transformers) (4.28.1)\n",
      "Requirement already satisfied: filelock in d:\\ai-youtube\\ai-youtube-search\\env\\lib\\site-packages (from huggingface-hub>=0.4.0->sentence-transformers) (3.10.7)\n",
      "Requirement already satisfied: pyyaml>=5.1 in d:\\ai-youtube\\ai-youtube-search\\env\\lib\\site-packages (from huggingface-hub>=0.4.0->sentence-transformers) (6.0)\n",
      "Requirement already satisfied: typing-extensions>=3.7.4.3 in d:\\ai-youtube\\ai-youtube-search\\env\\lib\\site-packages (from huggingface-hub>=0.4.0->sentence-transformers) (4.5.0)\n",
      "Requirement already satisfied: requests in d:\\ai-youtube\\ai-youtube-search\\env\\lib\\site-packages (from huggingface-hub>=0.4.0->sentence-transformers) (2.28.2)\n",
      "Requirement already satisfied: packaging>=20.9 in d:\\ai-youtube\\ai-youtube-search\\env\\lib\\site-packages (from huggingface-hub>=0.4.0->sentence-transformers) (23.1)\n",
      "Requirement already satisfied: sympy in d:\\ai-youtube\\ai-youtube-search\\env\\lib\\site-packages (from torch>=1.6.0->sentence-transformers) (1.11.1)\n",
      "Requirement already satisfied: jinja2 in d:\\ai-youtube\\ai-youtube-search\\env\\lib\\site-packages (from torch>=1.6.0->sentence-transformers) (3.1.2)\n",
      "Requirement already satisfied: networkx in d:\\ai-youtube\\ai-youtube-search\\env\\lib\\site-packages (from torch>=1.6.0->sentence-transformers) (3.0)\n",
      "Requirement already satisfied: colorama in d:\\ai-youtube\\ai-youtube-search\\env\\lib\\site-packages (from tqdm->sentence-transformers) (0.4.6)\n",
      "Requirement already satisfied: tokenizers!=0.11.3,<0.14,>=0.11.1 in d:\\ai-youtube\\ai-youtube-search\\env\\lib\\site-packages (from transformers<5.0.0,>=4.6.0->sentence-transformers) (0.13.3)\n",
      "Requirement already satisfied: regex!=2019.12.17 in d:\\ai-youtube\\ai-youtube-search\\env\\lib\\site-packages (from transformers<5.0.0,>=4.6.0->sentence-transformers) (2023.3.23)\n",
      "Requirement already satisfied: click in d:\\ai-youtube\\ai-youtube-search\\env\\lib\\site-packages (from nltk->sentence-transformers) (8.1.3)\n",
      "Requirement already satisfied: joblib in d:\\ai-youtube\\ai-youtube-search\\env\\lib\\site-packages (from nltk->sentence-transformers) (1.2.0)\n",
      "Requirement already satisfied: threadpoolctl>=2.0.0 in d:\\ai-youtube\\ai-youtube-search\\env\\lib\\site-packages (from scikit-learn->sentence-transformers) (3.1.0)\n",
      "Requirement already satisfied: pillow!=8.3.*,>=5.3.0 in d:\\ai-youtube\\ai-youtube-search\\env\\lib\\site-packages (from torchvision->sentence-transformers) (9.5.0)\n",
      "Requirement already satisfied: MarkupSafe>=2.0 in d:\\ai-youtube\\ai-youtube-search\\env\\lib\\site-packages (from jinja2->torch>=1.6.0->sentence-transformers) (2.1.2)\n",
      "Requirement already satisfied: urllib3<1.27,>=1.21.1 in d:\\ai-youtube\\ai-youtube-search\\env\\lib\\site-packages (from requests->huggingface-hub>=0.4.0->sentence-transformers) (1.26.15)\n",
      "Requirement already satisfied: certifi>=2017.4.17 in d:\\ai-youtube\\ai-youtube-search\\env\\lib\\site-packages (from requests->huggingface-hub>=0.4.0->sentence-transformers) (2022.12.7)\n",
      "Requirement already satisfied: charset-normalizer<4,>=2 in d:\\ai-youtube\\ai-youtube-search\\env\\lib\\site-packages (from requests->huggingface-hub>=0.4.0->sentence-transformers) (3.1.0)\n",
      "Requirement already satisfied: idna<4,>=2.5 in d:\\ai-youtube\\ai-youtube-search\\env\\lib\\site-packages (from requests->huggingface-hub>=0.4.0->sentence-transformers) (3.4)\n",
      "Requirement already satisfied: mpmath>=0.19 in d:\\ai-youtube\\ai-youtube-search\\env\\lib\\site-packages (from sympy->torch>=1.6.0->sentence-transformers) (1.3.0)\n",
      "Note: you may need to restart the kernel to use updated packages.\n"
     ]
    }
   ],
   "source": [
    "pip install -U sentence-transformers"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Embeddings computed. Shape: (90633, 384)\n"
     ]
    }
   ],
   "source": [
    "from sentence_transformers import SentenceTransformer\n",
    "\n",
    "#Create a large list of 100k sentences\n",
    "sentences = df['text']\n",
    "\n",
    "model = SentenceTransformer('all-MiniLM-L6-v2')\n",
    "#Start the multi-process pool on all available CUDA devices\n",
    "pool = model.start_multi_process_pool(['cpu','cpu','cpu'])\n",
    "\n",
    "#Compute the embeddings using the multi-process pool\n",
    "final_emb = model.encode_multi_process(sentences, pool)\n",
    "print(\"Embeddings computed. Shape:\", final_emb.shape)\n",
    "\n",
    "#Optional: Stop the proccesses in the pool\n",
    "model.stop_multi_process_pool(pool)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "90633"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(final_emb)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(90633, 384)"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "final_emb.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "384"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "d=final_emb.shape[1]\n",
    "d"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "index=faiss.IndexFlatL2(d)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "index.is_trained"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "index.add(final_emb)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "90633"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "index.ntotal"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "xq=model.encode(['what is bootstrap'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[48901 30687 30686 14421  1413]]\n",
      "[[0.7749672  0.8113897  0.83024615 0.9622795  0.99349165]]\n",
      "CPU times: total: 46.9 ms\n",
      "Wall time: 1.52 s\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "D, I = index.search(xq,5)\n",
    "print(I)\n",
    "print(D)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "lines=df['text']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[\"48901: and stuff like that I'll show you exactly the process I go through. So Bootstrap has a website and you go there and you can kind of look at their examples of things that you can do with Bootstrap and then you just basically copy and paste and kind of edit and change. So it's actually a lot easier than it might seem. So with that let's go ahead and get started.\",\n",
       " \"30687: So we have some cool examples here so this is one card we can go down a little bit more or this one I think this is probably the one I'll use. Okay so basically Bootstrap is like a framework which is pretty lightweight and you have all these really nice examples of how you can build something that was super nice. So what we can do is actually just copy this, we'll go back over to our code and what I'm going to do is I'm going to create the definition for one of these cards.\",\n",
       " \"30686: So if I just type in Bootstrap cards, you can see it's in my history but I'm going to just put Bootstrap cards for now so you can follow and go on here and let's make this a little bit bigger, zoom in a little bit and scroll down. So we have some cool examples here so this is one card we can go down a little bit more or this one I think this is probably the one I'll use. Okay so basically Bootstrap is like a framework which is pretty lightweight and you have all\",\n",
       " \"14421:  them there I'll I'll read them through it'll be fun alright so they say we introduced bootstrap your own latent or be all a new approach to self supervised image representation learning ok so image representation learning is the simple task of taking an image and then feeding it through a function which is usually like a neural network let's let's just say this is a neural network\",\n",
       " \"1413:  To create a bootstrap dataset that is the same size as the original, we just randomly select samples from the original dataset. The important detail is that we're allowed to pick the same sample more than once. This is the first sample that we randomly select. So it's the first sample in our bootstrap dataset.\"]"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "[f'{i}: {lines[i]}' for i in I[0]]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "xq2=model.encode(['what is cross validation'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[38113 38111 38074 38068    28]]\n",
      "[[0.6957379  0.7749776  0.8071182  0.83150375 0.84595877]]\n",
      "CPU times: total: 62.5 ms\n",
      "Wall time: 62.4 ms\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "D2, I2 = index.search(xq2,5)\n",
    "print(I2)\n",
    "print(D2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[\"38113: to explain cross validation and how I understand it I would I would look into it into it yourself as another piece of homework but if you imagine if you imagine let's let's do this let's use a piece of paper while cat boost is running we've got a little countdown here so you've got some time to play with imagine you have your data here right just as one simple piece of paper right and you do one your model goes down and it fits all the rows in one hit okay it might have done a really good job right because some of what it does is randomly initialized what does that mean so\",\n",
       " \"38111: what it does and now I actually can't couldn't explain to you what what it does on the inside but just in my experience of using it multiple times for multiple projects it does take a little bit to run because I think I think it's doing a combination of different types of models so it's not just doing one one one single way of fitting on the data it's doing it's doing multiple different ways so it's doing a decision tree classifier and a gradient boosted tree all all rolled into one so we're fitting that here now why would you want to perform cross validation all right so I'm going\",\n",
       " \"38074: one pass and then accuracy of cross fold validation on 78.5% now why would you want to do cross-validation validation we'll get to that we'll get to that in a minute we're gonna run all the other algorithms first so k nearest neighbors now these are what actually what are these what algorithms are we running so we go up into sklearn and if you if you look here we've imported a bunch of different algorithms here okay now these are some of the most common machine learning algorithms that you'll see all right now if you google most common machine learning algorithms these will probably\",\n",
       " \"38068: and a set of labels now we can run some machine learning on it so we've built a little function here because we're going to be running multiple different machine learning algorithms called fit ML algo now this is it takes an algorithm a type of algorithm it takes a set of data it takes some labels it takes a number of times you want to cross validate right so cross validate is important we'll get on to that in a second it's gonna do it's gonna create the model then it's gonna fit fit the algorithm to the training data and the labels it's gonna give us an accuracy accuracy\",\n",
       " \"28:  SetQuest, check it out, talking about machine learning. SetQuest, check it out, talking about cross validation. SetQuest. Hello, I'm Josh Starmer and welcome to SetQuest. Today we're going to talk about cross validation and it's going to be clearly explained.\"]"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "[f'{i}: {lines[i]}' for i in I2[0]]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [],
   "source": [
    "nlist=10\n",
    "quantizer=faiss.IndexFlatL2(d)\n",
    "index=faiss.IndexIVFFlat(quantizer,d,nlist)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "False"
      ]
     },
     "execution_count": 37,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "index.is_trained"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [],
   "source": [
    "index.train(embeddings)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [],
   "source": [
    "index.add(embeddings)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "32"
      ]
     },
     "execution_count": 40,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "index.ntotal"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[ 5 13 12 11  4]]\n",
      "CPU times: total: 0 ns\n",
      "Wall time: 3 ms\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "D, I =index.search(xq,5)\n",
    "print(I)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[\"5:  To create a bootstrap dataset that is the same size as the original, we just randomly select samples from the original dataset. The important detail is that we're allowed to pick the same sample more than once. This is the first sample that we randomly select.\",\n",
       " \"13:  Using a bootstrap sample and considering only a subset of variables at each step results in a wide variety of trees. The variety is what makes random forests more effective than individual decision trees. Sweet. Now that we've created a random forest, how do we use it?\",\n",
       " '12:  Now, go back to step one and repeat. Make a new bootstrap dataset and build a tree considering a subset of variables at each step. Ideally, you do this hundreds of times, but we only have space to show six. But you get the idea.',\n",
       " \"11:  And we just build the tree as usual, but only considering a random subset of variables at each step. Double bound. We built a tree, one, using a bootstrap dataset, and two, only considering a random subset of variables at each step. Here's the tree we just made.\",\n",
       " \"4:  Step one, create a bootstrap dataset. Imagine that these four samples are the entire dataset that we are going to build a tree from. I know it's crazy small, but just pretend for now.\"]"
      ]
     },
     "execution_count": 42,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "[f'{i}: {lines[i]}' for i in I[0]]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {},
   "outputs": [],
   "source": [
    "m=8\n",
    "bits=5\n",
    "\n",
    "quantizer=faiss.IndexFlatL2(d)\n",
    "index=faiss.IndexIVFPQ(quantizer,d,16,m,bits)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "False"
      ]
     },
     "execution_count": 50,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "index.is_trained"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {},
   "outputs": [],
   "source": [
    "index.train(embeddings)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "metadata": {},
   "outputs": [],
   "source": [
    "index.add(embeddings)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[ 5  7 12 -1 -1]]\n",
      "CPU times: total: 31.2 ms\n",
      "Wall time: 1.26 s\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "D, I =index.search(xq,5)\n",
    "print(I)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import faiss"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(128, 6)"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df1=pd.read_csv('data_set.csv')\n",
    "df1.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Embeddings computed. Shape: (128, 384)\n"
     ]
    }
   ],
   "source": [
    "from sentence_transformers import SentenceTransformer\n",
    "\n",
    "#Create a large list of 100k sentences\n",
    "sentences = df1['text']\n",
    "\n",
    "model = SentenceTransformer('all-MiniLM-L6-v2')\n",
    "#Start the multi-process pool on all available CUDA devices\n",
    "pool = model.start_multi_process_pool(['cpu','cpu','cpu'])\n",
    "\n",
    "#Compute the embeddings using the multi-process pool\n",
    "final_emb = model.encode_multi_process(sentences, pool)\n",
    "print(\"Embeddings computed. Shape:\", final_emb.shape)\n",
    "\n",
    "#Optional: Stop the proccesses in the pool\n",
    "model.stop_multi_process_pool(pool)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "384"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "d=final_emb.shape[1]\n",
    "d"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "index=faiss.IndexFlatL2(d)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "index.is_trained"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "index.ntotal"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "index.add(final_emb)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "xq=model.encode(['what is bootstrap'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[32 20 26 24 28]]\n",
      "CPU times: total: 0 ns\n",
      "Wall time: 712 ms\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "D, I =index.search(xq,5)\n",
    "print(I)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [],
   "source": [
    "s=df1.loc[I[0],['url','start']]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'https://www.youtube.com/watch?v=J4Wdy0Wc_xQ?t=91.76'"
      ]
     },
     "execution_count": 40,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "url=df1['url']\n",
    "start=df1['start']\n",
    "l=[df1['url'][i]+'?t='+str(df1['start'][i]) for i in I[0]]\n",
    "l[1]\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'32    138.84\\n20     91.76\\n26    119.00\\n24    109.76\\n28    126.40\\nName: start, dtype: float64'"
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "str(df1['start'][I[0]])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.16"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
