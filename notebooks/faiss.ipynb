{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>title</th>\n",
       "      <th>start</th>\n",
       "      <th>end</th>\n",
       "      <th>text</th>\n",
       "      <th>duration</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>StatQuest: Random Forests Part 1 - Building, U...</td>\n",
       "      <td>0.00</td>\n",
       "      <td>23.04</td>\n",
       "      <td>Wandering around, around them, forest, I won'...</td>\n",
       "      <td>23.04</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>StatQuest: Random Forests Part 1 - Building, U...</td>\n",
       "      <td>23.04</td>\n",
       "      <td>41.72</td>\n",
       "      <td>Note, random forests are built from decision ...</td>\n",
       "      <td>18.68</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>StatQuest: Random Forests Part 1 - Building, U...</td>\n",
       "      <td>41.72</td>\n",
       "      <td>61.36</td>\n",
       "      <td>To quote from the elements of statistical lea...</td>\n",
       "      <td>19.64</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>StatQuest: Random Forests Part 1 - Building, U...</td>\n",
       "      <td>61.36</td>\n",
       "      <td>77.72</td>\n",
       "      <td>when it comes to classifying new samples. The...</td>\n",
       "      <td>16.36</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>StatQuest: Random Forests Part 1 - Building, U...</td>\n",
       "      <td>77.72</td>\n",
       "      <td>91.76</td>\n",
       "      <td>Step one, create a bootstrap dataset. Imagine...</td>\n",
       "      <td>14.04</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                               title  start    end  \\\n",
       "0  StatQuest: Random Forests Part 1 - Building, U...   0.00  23.04   \n",
       "1  StatQuest: Random Forests Part 1 - Building, U...  23.04  41.72   \n",
       "2  StatQuest: Random Forests Part 1 - Building, U...  41.72  61.36   \n",
       "3  StatQuest: Random Forests Part 1 - Building, U...  61.36  77.72   \n",
       "4  StatQuest: Random Forests Part 1 - Building, U...  77.72  91.76   \n",
       "\n",
       "                                                text  duration  \n",
       "0   Wandering around, around them, forest, I won'...     23.04  \n",
       "1   Note, random forests are built from decision ...     18.68  \n",
       "2   To quote from the elements of statistical lea...     19.64  \n",
       "3   when it comes to classifying new samples. The...     16.36  \n",
       "4   Step one, create a bootstrap dataset. Imagine...     14.04  "
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import pandas as pd\n",
    "\n",
    "df =pd.read_csv('Final_data_set.csv')\n",
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0      Wandering around, around them, forest, I won'...\n",
       "1      Note, random forests are built from decision ...\n",
       "2      To quote from the elements of statistical lea...\n",
       "3      when it comes to classifying new samples. The...\n",
       "4      Step one, create a bootstrap dataset. Imagine...\n",
       "5      To create a bootstrap dataset that is the sam...\n",
       "6      So it's the first sample in our bootstrap dat...\n",
       "7      So here it is in the bootstrap dataset. Lastl...\n",
       "8      Bam, we've created a bootstrap dataset. Step ...\n",
       "9      Note, we'll talk more about how to determine ...\n",
       "10     Just for the sake of the example, assume that...\n",
       "11     And we just build the tree as usual, but only...\n",
       "12     Now, go back to step one and repeat. Make a n...\n",
       "13     Using a bootstrap sample and considering only...\n",
       "14     Well, first we get a new patient. We've got a...\n",
       "15     Boobedoo,onym, ar, ba,doo, tim rebo, the firs...\n",
       "16     And we keep track of that. For all the trees ...\n",
       "17     In this case, yes received the most votes, so...\n",
       "18     Boots strapping the data, plus using the aggr...\n",
       "19     Remember when we created the Boots strapped d...\n",
       "20     set. Here's the entry that didn't end up in t...\n",
       "21     This is called the Out of Bag Data Set. If it...\n",
       "22     Since the Out of Bag Data was not used to cre...\n",
       "23     it. This tree incorrectly labeled the Out of ...\n",
       "24     sample. In this case, the Out of Bag sample i...\n",
       "25     This Out of Bag sample was incorrectly labele...\n",
       "26     Ultimately, we can measure how accurate our r...\n",
       "27     OK. We now know how to 1 build a random fores...\n",
       "28     Remember when we built our first tree and we ...\n",
       "29     We test a bunch of different settings and cho...\n",
       "30     then choose the one that is the most accurate...\n",
       "31     Hooray, we've made it to the end of another e...\n",
       "Name: text, dtype: object"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df['text']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Collecting package metadata (current_repodata.json): ...working... done\n",
      "Solving environment: ...working... done\n",
      "\n",
      "## Package Plan ##\n",
      "\n",
      "  environment location: d:\\AI-youtube\\ai-youtube-search\\env\n",
      "\n",
      "  added / updated specs:\n",
      "    - faiss-cpu\n",
      "\n",
      "\n",
      "The following packages will be downloaded:\n",
      "\n",
      "    package                    |            build\n",
      "    ---------------------------|-----------------\n",
      "    faiss-cpu-1.7.3            |py3.8_h2272212_106_cpu_nightly         1.4 MB  pytorch/label/nightly\n",
      "    libfaiss-1.7.3             |h2e52968_106_cpu_nightly         1.3 MB  pytorch/label/nightly\n",
      "    ------------------------------------------------------------\n",
      "                                           Total:         2.6 MB\n",
      "\n",
      "The following NEW packages will be INSTALLED:\n",
      "\n",
      "  blas               pkgs/main/win-64::blas-1.0-mkl \n",
      "  faiss-cpu          pytorch/label/nightly/win-64::faiss-cpu-1.7.3-py3.8_h2272212_106_cpu_nightly \n",
      "  intel-openmp       pkgs/main/win-64::intel-openmp-2021.4.0-haa95532_3556 \n",
      "  libfaiss           pytorch/label/nightly/win-64::libfaiss-1.7.3-h2e52968_106_cpu_nightly \n",
      "  mkl                pkgs/main/win-64::mkl-2021.4.0-haa95532_640 \n",
      "  mkl-service        pkgs/main/win-64::mkl-service-2.4.0-py38h2bbff1b_0 \n",
      "  mkl_fft            pkgs/main/win-64::mkl_fft-1.3.1-py38h277e83a_0 \n",
      "  mkl_random         pkgs/main/win-64::mkl_random-1.2.2-py38hf11a4ad_0 \n",
      "  numpy              pkgs/main/win-64::numpy-1.23.5-py38h3b20f71_0 \n",
      "  numpy-base         pkgs/main/win-64::numpy-base-1.23.5-py38h4da318b_0 \n",
      "\n",
      "The following packages will be UPDATED:\n",
      "\n",
      "  ca-certificates    conda-forge::ca-certificates-2022.12.~ --> pkgs/main::ca-certificates-2023.01.10-haa95532_0 \n",
      "\n",
      "The following packages will be SUPERSEDED by a higher-priority channel:\n",
      "\n",
      "  certifi            conda-forge/noarch::certifi-2022.12.7~ --> pkgs/main/win-64::certifi-2022.12.7-py38haa95532_0 \n",
      "\n",
      "\n",
      "\n",
      "Downloading and Extracting Packages\n",
      "\n",
      "faiss-cpu-1.7.3      | 1.4 MB    |            |   0% \n",
      "\n",
      "libfaiss-1.7.3       | 1.3 MB    |            |   0% \u001b[A\n",
      "\n",
      "libfaiss-1.7.3       | 1.3 MB    | 1          |   1% \u001b[A\n",
      "\n",
      "libfaiss-1.7.3       | 1.3 MB    | 2          |   2% \u001b[A\n",
      "\n",
      "libfaiss-1.7.3       | 1.3 MB    | 4          |   5% \u001b[A\n",
      "\n",
      "libfaiss-1.7.3       | 1.3 MB    | 9          |  10% \u001b[A\n",
      "faiss-cpu-1.7.3      | 1.4 MB    | 1          |   1% \n",
      "\n",
      "libfaiss-1.7.3       | 1.3 MB    | #3         |  14% \u001b[A\n",
      "\n",
      "libfaiss-1.7.3       | 1.3 MB    | #7         |  17% \u001b[A\n",
      "faiss-cpu-1.7.3      | 1.4 MB    | 2          |   2% \n",
      "\n",
      "libfaiss-1.7.3       | 1.3 MB    | #8         |  19% \u001b[A\n",
      "\n",
      "libfaiss-1.7.3       | 1.3 MB    | #9         |  20% \u001b[A\n",
      "faiss-cpu-1.7.3      | 1.4 MB    | 3          |   3% \n",
      "\n",
      "libfaiss-1.7.3       | 1.3 MB    | ##2        |  22% \u001b[A\n",
      "\n",
      "libfaiss-1.7.3       | 1.3 MB    | ##3        |  24% \u001b[A\n",
      "faiss-cpu-1.7.3      | 1.4 MB    | 4          |   5% \n",
      "\n",
      "libfaiss-1.7.3       | 1.3 MB    | ##4        |  25% \u001b[A\n",
      "\n",
      "libfaiss-1.7.3       | 1.3 MB    | ##6        |  26% \u001b[A\n",
      "\n",
      "libfaiss-1.7.3       | 1.3 MB    | ##7        |  27% \u001b[A\n",
      "\n",
      "libfaiss-1.7.3       | 1.3 MB    | ##8        |  29% \u001b[A\n",
      "faiss-cpu-1.7.3      | 1.4 MB    | 5          |   6% \n",
      "\n",
      "libfaiss-1.7.3       | 1.3 MB    | ##9        |  30% \u001b[A\n",
      "\n",
      "libfaiss-1.7.3       | 1.3 MB    | ###1       |  31% \u001b[A\n",
      "faiss-cpu-1.7.3      | 1.4 MB    | 6          |   7% \n",
      "\n",
      "libfaiss-1.7.3       | 1.3 MB    | ###2       |  32% \u001b[A\n",
      "\n",
      "libfaiss-1.7.3       | 1.3 MB    | ###3       |  34% \u001b[A\n",
      "\n",
      "libfaiss-1.7.3       | 1.3 MB    | ###4       |  35% \u001b[A\n",
      "\n",
      "libfaiss-1.7.3       | 1.3 MB    | ###6       |  36% \u001b[A\n",
      "faiss-cpu-1.7.3      | 1.4 MB    | 9          |   9% \n",
      "\n",
      "libfaiss-1.7.3       | 1.3 MB    | ###7       |  37% \u001b[A\n",
      "\n",
      "libfaiss-1.7.3       | 1.3 MB    | ###8       |  39% \u001b[A\n",
      "faiss-cpu-1.7.3      | 1.4 MB    | #          |  10% \n",
      "\n",
      "libfaiss-1.7.3       | 1.3 MB    | ###9       |  40% \u001b[A\n",
      "faiss-cpu-1.7.3      | 1.4 MB    | #1         |  12% \n",
      "\n",
      "libfaiss-1.7.3       | 1.3 MB    | ####1      |  41% \u001b[A\n",
      "\n",
      "libfaiss-1.7.3       | 1.3 MB    | ####2      |  42% \u001b[A\n",
      "faiss-cpu-1.7.3      | 1.4 MB    | #2         |  13% \n",
      "faiss-cpu-1.7.3      | 1.4 MB    | #3         |  14% \n",
      "\n",
      "libfaiss-1.7.3       | 1.3 MB    | ####3      |  44% \u001b[A\n",
      "faiss-cpu-1.7.3      | 1.4 MB    | #4         |  15% \n",
      "faiss-cpu-1.7.3      | 1.4 MB    | #6         |  16% \n",
      "faiss-cpu-1.7.3      | 1.4 MB    | #7         |  17% \n",
      "\n",
      "libfaiss-1.7.3       | 1.3 MB    | ####4      |  45% \u001b[A\n",
      "faiss-cpu-1.7.3      | 1.4 MB    | #8         |  18% \n",
      "faiss-cpu-1.7.3      | 1.4 MB    | #9         |  20% \n",
      "faiss-cpu-1.7.3      | 1.4 MB    | ##         |  21% \n",
      "\n",
      "libfaiss-1.7.3       | 1.3 MB    | ####6      |  46% \u001b[A\n",
      "faiss-cpu-1.7.3      | 1.4 MB    | ##3        |  23% \n",
      "\n",
      "libfaiss-1.7.3       | 1.3 MB    | ####7      |  47% \u001b[A\n",
      "faiss-cpu-1.7.3      | 1.4 MB    | ##4        |  24% \n",
      "faiss-cpu-1.7.3      | 1.4 MB    | ##5        |  25% \n",
      "\n",
      "libfaiss-1.7.3       | 1.3 MB    | ####8      |  49% \u001b[A\n",
      "faiss-cpu-1.7.3      | 1.4 MB    | ##6        |  26% \n",
      "faiss-cpu-1.7.3      | 1.4 MB    | ##7        |  28% \n",
      "faiss-cpu-1.7.3      | 1.4 MB    | ##8        |  29% \n",
      "\n",
      "libfaiss-1.7.3       | 1.3 MB    | #####1     |  51% \u001b[A\n",
      "faiss-cpu-1.7.3      | 1.4 MB    | ##9        |  30% \n",
      "\n",
      "libfaiss-1.7.3       | 1.3 MB    | #####3     |  54% \u001b[A\n",
      "faiss-cpu-1.7.3      | 1.4 MB    | ###1       |  31% \n",
      "\n",
      "libfaiss-1.7.3       | 1.3 MB    | #####4     |  55% \u001b[A\n",
      "\n",
      "libfaiss-1.7.3       | 1.3 MB    | #####6     |  56% \u001b[A\n",
      "faiss-cpu-1.7.3      | 1.4 MB    | ###2       |  32% \n",
      "\n",
      "libfaiss-1.7.3       | 1.3 MB    | #####7     |  57% \u001b[A\n",
      "\n",
      "libfaiss-1.7.3       | 1.3 MB    | #####9     |  60% \u001b[A\n",
      "\n",
      "libfaiss-1.7.3       | 1.3 MB    | ######1    |  61% \u001b[A\n",
      "\n",
      "libfaiss-1.7.3       | 1.3 MB    | ######2    |  62% \u001b[A\n",
      "\n",
      "libfaiss-1.7.3       | 1.3 MB    | ######4    |  65% \u001b[A\n",
      "\n",
      "libfaiss-1.7.3       | 1.3 MB    | ######6    |  66% \u001b[A\n",
      "faiss-cpu-1.7.3      | 1.4 MB    | ###4       |  35% \n",
      "\n",
      "libfaiss-1.7.3       | 1.3 MB    | ######7    |  67% \u001b[A\n",
      "\n",
      "libfaiss-1.7.3       | 1.3 MB    | ######8    |  69% \u001b[A\n",
      "faiss-cpu-1.7.3      | 1.4 MB    | ###6       |  37% \n",
      "\n",
      "libfaiss-1.7.3       | 1.3 MB    | ######9    |  70% \u001b[A\n",
      "faiss-cpu-1.7.3      | 1.4 MB    | ###7       |  38% \n",
      "\n",
      "libfaiss-1.7.3       | 1.3 MB    | #######2   |  72% \u001b[A\n",
      "faiss-cpu-1.7.3      | 1.4 MB    | ###9       |  39% \n",
      "\n",
      "libfaiss-1.7.3       | 1.3 MB    | #######4   |  75% \u001b[A\n",
      "faiss-cpu-1.7.3      | 1.4 MB    | ####1      |  41% \n",
      "\n",
      "libfaiss-1.7.3       | 1.3 MB    | #######6   |  76% \u001b[A\n",
      "faiss-cpu-1.7.3      | 1.4 MB    | ####2      |  43% \n",
      "\n",
      "libfaiss-1.7.3       | 1.3 MB    | #######7   |  77% \u001b[A\n",
      "faiss-cpu-1.7.3      | 1.4 MB    | ####3      |  44% \n",
      "\n",
      "libfaiss-1.7.3       | 1.3 MB    | #######9   |  80% \u001b[A\n",
      "faiss-cpu-1.7.3      | 1.4 MB    | ####4      |  45% \n",
      "faiss-cpu-1.7.3      | 1.4 MB    | ####6      |  46% \n",
      "\n",
      "libfaiss-1.7.3       | 1.3 MB    | ########1  |  81% \u001b[A\n",
      "faiss-cpu-1.7.3      | 1.4 MB    | ####7      |  47% \n",
      "\n",
      "libfaiss-1.7.3       | 1.3 MB    | ########2  |  82% \u001b[A\n",
      "\n",
      "libfaiss-1.7.3       | 1.3 MB    | ########3  |  84% \u001b[A\n",
      "faiss-cpu-1.7.3      | 1.4 MB    | ####8      |  48% \n",
      "\n",
      "libfaiss-1.7.3       | 1.3 MB    | ########4  |  85% \u001b[A\n",
      "faiss-cpu-1.7.3      | 1.4 MB    | ####9      |  49% \n",
      "\n",
      "libfaiss-1.7.3       | 1.3 MB    | ########6  |  86% \u001b[A\n",
      "\n",
      "libfaiss-1.7.3       | 1.3 MB    | ########7  |  87% \u001b[A\n",
      "faiss-cpu-1.7.3      | 1.4 MB    | #####      |  51% \n",
      "faiss-cpu-1.7.3      | 1.4 MB    | #####1     |  52% \n",
      "\n",
      "libfaiss-1.7.3       | 1.3 MB    | ########9  |  90% \u001b[A\n",
      "faiss-cpu-1.7.3      | 1.4 MB    | #####2     |  53% \n",
      "faiss-cpu-1.7.3      | 1.4 MB    | #####4     |  54% \n",
      "\n",
      "libfaiss-1.7.3       | 1.3 MB    | #########2 |  92% \u001b[A\n",
      "faiss-cpu-1.7.3      | 1.4 MB    | #####5     |  55% \n",
      "faiss-cpu-1.7.3      | 1.4 MB    | #####6     |  56% \n",
      "\n",
      "libfaiss-1.7.3       | 1.3 MB    | #########4 |  95% \u001b[A\n",
      "\n",
      "libfaiss-1.7.3       | 1.3 MB    | #########7 |  97% \u001b[A\n",
      "faiss-cpu-1.7.3      | 1.4 MB    | #####7     |  58% \n",
      "\n",
      "libfaiss-1.7.3       | 1.3 MB    | #########8 |  98% \u001b[A\n",
      "\n",
      "libfaiss-1.7.3       | 1.3 MB    | #########9 | 100% \u001b[A\n",
      "faiss-cpu-1.7.3      | 1.4 MB    | #####9     |  60% \n",
      "faiss-cpu-1.7.3      | 1.4 MB    | ######2    |  62% \n",
      "\n",
      "libfaiss-1.7.3       | 1.3 MB    | ########## | 100% \u001b[A\n",
      "faiss-cpu-1.7.3      | 1.4 MB    | ######3    |  63% \n",
      "faiss-cpu-1.7.3      | 1.4 MB    | ######4    |  64% \n",
      "faiss-cpu-1.7.3      | 1.4 MB    | ######6    |  67% \n",
      "faiss-cpu-1.7.3      | 1.4 MB    | ######7    |  68% \n",
      "faiss-cpu-1.7.3      | 1.4 MB    | ######9    |  69% \n",
      "faiss-cpu-1.7.3      | 1.4 MB    | #######    |  70% \n",
      "faiss-cpu-1.7.3      | 1.4 MB    | #######1   |  71% \n",
      "faiss-cpu-1.7.3      | 1.4 MB    | #######2   |  72% \n",
      "faiss-cpu-1.7.3      | 1.4 MB    | #######3   |  74% \n",
      "faiss-cpu-1.7.3      | 1.4 MB    | #######4   |  75% \n",
      "faiss-cpu-1.7.3      | 1.4 MB    | #######5   |  76% \n",
      "faiss-cpu-1.7.3      | 1.4 MB    | #######7   |  77% \n",
      "faiss-cpu-1.7.3      | 1.4 MB    | #######8   |  78% \n",
      "faiss-cpu-1.7.3      | 1.4 MB    | #######9   |  79% \n",
      "faiss-cpu-1.7.3      | 1.4 MB    | ########   |  81% \n",
      "faiss-cpu-1.7.3      | 1.4 MB    | ########1  |  82% \n",
      "faiss-cpu-1.7.3      | 1.4 MB    | ########2  |  83% \n",
      "faiss-cpu-1.7.3      | 1.4 MB    | ########3  |  84% \n",
      "faiss-cpu-1.7.3      | 1.4 MB    | ########5  |  85% \n",
      "faiss-cpu-1.7.3      | 1.4 MB    | ########6  |  86% \n",
      "faiss-cpu-1.7.3      | 1.4 MB    | ########7  |  87% \n",
      "faiss-cpu-1.7.3      | 1.4 MB    | ########8  |  89% \n",
      "faiss-cpu-1.7.3      | 1.4 MB    | ########9  |  90% \n",
      "faiss-cpu-1.7.3      | 1.4 MB    | #########  |  91% \n",
      "faiss-cpu-1.7.3      | 1.4 MB    | #########2 |  92% \n",
      "faiss-cpu-1.7.3      | 1.4 MB    | #########3 |  93% \n",
      "faiss-cpu-1.7.3      | 1.4 MB    | #########4 |  94% \n",
      "faiss-cpu-1.7.3      | 1.4 MB    | #########5 |  95% \n",
      "faiss-cpu-1.7.3      | 1.4 MB    | #########6 |  97% \n",
      "faiss-cpu-1.7.3      | 1.4 MB    | #########7 |  98% \n",
      "faiss-cpu-1.7.3      | 1.4 MB    | #########8 |  99% \n",
      "faiss-cpu-1.7.3      | 1.4 MB    | ########## | 100% \n",
      "faiss-cpu-1.7.3      | 1.4 MB    | ########## | 100% \n",
      "                                                     \n",
      "\n",
      "\n",
      "                                                     \u001b[A\n",
      "\n",
      "Preparing transaction: ...working... done\n",
      "Verifying transaction: ...working... done\n",
      "Executing transaction: ...working... done\n",
      "\n",
      "Note: you may need to restart the kernel to use updated packages.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "==> WARNING: A newer version of conda exists. <==\n",
      "  current version: 23.3.0\n",
      "  latest version: 23.3.1\n",
      "\n",
      "Please update conda by running\n",
      "\n",
      "    $ conda update -n base -c defaults conda\n",
      "\n",
      "Or to minimize the number of packages updated during conda update use\n",
      "\n",
      "     conda install conda=23.3.1\n",
      "\n",
      "\n"
     ]
    }
   ],
   "source": [
    "conda install -c pytorch/label/nightly faiss-cpu"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Collecting faiss-gpu\n",
      "  Downloading faiss-gpu-1.7.1.post2.tar.gz (40 kB)\n",
      "     -------------------------------------- 40.3/40.3 kB 319.9 kB/s eta 0:00:00\n",
      "  Preparing metadata (setup.py): started\n",
      "  Preparing metadata (setup.py): finished with status 'done'\n",
      "Discarding https://files.pythonhosted.org/packages/17/76/47d0cc8161f4bf988583a2839bb1e56baf09d6b80cfa472b9eba4d5f543b/faiss-gpu-1.7.1.post2.tar.gz (from https://pypi.org/simple/faiss-gpu/): Requested faiss-cpu from https://files.pythonhosted.org/packages/17/76/47d0cc8161f4bf988583a2839bb1e56baf09d6b80cfa472b9eba4d5f543b/faiss-gpu-1.7.1.post2.tar.gz has inconsistent name: expected 'faiss-gpu', but metadata has 'faiss-cpu'\n",
      "  Downloading faiss-gpu-1.7.1.post1.tar.gz (41 kB)\n",
      "     -------------------------------------- 41.1/41.1 kB 395.7 kB/s eta 0:00:00\n",
      "  Preparing metadata (setup.py): started\n",
      "  Preparing metadata (setup.py): finished with status 'done'\n",
      "Discarding https://files.pythonhosted.org/packages/39/8d/b62bc92c8dd4b2a99d4a06b8804280f6445748b6d698eabb037e111080c7/faiss-gpu-1.7.1.post1.tar.gz (from https://pypi.org/simple/faiss-gpu/): Requested faiss-cpu from https://files.pythonhosted.org/packages/39/8d/b62bc92c8dd4b2a99d4a06b8804280f6445748b6d698eabb037e111080c7/faiss-gpu-1.7.1.post1.tar.gz has inconsistent name: expected 'faiss-gpu', but metadata has 'faiss-cpu'\n",
      "  Downloading faiss-gpu-1.7.1.tar.gz (40 kB)\n",
      "     --------------------------------------- 40.3/40.3 kB 24.1 kB/s eta 0:00:00\n",
      "  Preparing metadata (setup.py): started\n",
      "  Preparing metadata (setup.py): finished with status 'done'\n",
      "Discarding https://files.pythonhosted.org/packages/51/85/7a7490dbecaea9272953b88e236a45fe8c47571a069bc28b352f0b224ea3/faiss-gpu-1.7.1.tar.gz (from https://pypi.org/simple/faiss-gpu/): Requested faiss-cpu from https://files.pythonhosted.org/packages/51/85/7a7490dbecaea9272953b88e236a45fe8c47571a069bc28b352f0b224ea3/faiss-gpu-1.7.1.tar.gz has inconsistent name: expected 'faiss-gpu', but metadata has 'faiss-cpu'\n",
      "  Downloading faiss-gpu-1.7.0.tar.gz (34 kB)\n",
      "  Preparing metadata (setup.py): started\n",
      "  Preparing metadata (setup.py): finished with status 'done'\n",
      "Discarding https://files.pythonhosted.org/packages/63/15/289ecf5d23f209c4c6f2f5f4db1d2b4a2be22d1fc49619354363e9367c19/faiss-gpu-1.7.0.tar.gz (from https://pypi.org/simple/faiss-gpu/): Requested faiss-cpu from https://files.pythonhosted.org/packages/63/15/289ecf5d23f209c4c6f2f5f4db1d2b4a2be22d1fc49619354363e9367c19/faiss-gpu-1.7.0.tar.gz has inconsistent name: expected 'faiss-gpu', but metadata has 'faiss-cpu'\n",
      "  Downloading faiss-gpu-1.6.5.tar.gz (28 kB)\n",
      "  Preparing metadata (setup.py): started\n",
      "  Preparing metadata (setup.py): finished with status 'done'\n",
      "Discarding https://files.pythonhosted.org/packages/9c/27/3477c856ea3d678619c33ae72f89ede4fbe08e9c5ba3b89a5feb3d9938b0/faiss-gpu-1.6.5.tar.gz (from https://pypi.org/simple/faiss-gpu/): Requested faiss-cpu from https://files.pythonhosted.org/packages/9c/27/3477c856ea3d678619c33ae72f89ede4fbe08e9c5ba3b89a5feb3d9938b0/faiss-gpu-1.6.5.tar.gz has inconsistent name: expected 'faiss-gpu', but metadata has 'faiss-cpu'\n",
      "  Downloading faiss-gpu-1.6.4.post2.tar.gz (25 kB)\n",
      "  Preparing metadata (setup.py): started\n",
      "  Preparing metadata (setup.py): finished with status 'done'\n",
      "Discarding https://files.pythonhosted.org/packages/7d/00/b3aaad408a44e4f5d87ebfcd75d0b14eeaed9fe9bc7a9f5e185ff1d503d6/faiss-gpu-1.6.4.post2.tar.gz (from https://pypi.org/simple/faiss-gpu/): Requested faiss-cpu from https://files.pythonhosted.org/packages/7d/00/b3aaad408a44e4f5d87ebfcd75d0b14eeaed9fe9bc7a9f5e185ff1d503d6/faiss-gpu-1.6.4.post2.tar.gz has inconsistent name: expected 'faiss-gpu', but metadata has 'faiss-cpu'\n",
      "  Downloading faiss-gpu-1.6.4.tar.gz (3.4 kB)\n",
      "  Preparing metadata (setup.py): started\n",
      "  Preparing metadata (setup.py): finished with status 'error'\n",
      "Note: you may need to restart the kernel to use updated packages.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  WARNING: Generating metadata for package faiss-gpu produced metadata for project name faiss-cpu. Fix your #egg=faiss-gpu fragments.\n",
      "  WARNING: Generating metadata for package faiss-gpu produced metadata for project name faiss-cpu. Fix your #egg=faiss-gpu fragments.\n",
      "  WARNING: Generating metadata for package faiss-gpu produced metadata for project name faiss-cpu. Fix your #egg=faiss-gpu fragments.\n",
      "  WARNING: Generating metadata for package faiss-gpu produced metadata for project name faiss-cpu. Fix your #egg=faiss-gpu fragments.\n",
      "  WARNING: Generating metadata for package faiss-gpu produced metadata for project name faiss-cpu. Fix your #egg=faiss-gpu fragments.\n",
      "  WARNING: Generating metadata for package faiss-gpu produced metadata for project name faiss-cpu. Fix your #egg=faiss-gpu fragments.\n",
      "  error: subprocess-exited-with-error\n",
      "  \n",
      "  × python setup.py egg_info did not run successfully.\n",
      "  │ exit code: 1\n",
      "  ╰─> [7 lines of output]\n",
      "      running egg_info\n",
      "      creating C:\\Users\\SAGAR\\AppData\\Local\\Temp\\pip-pip-egg-info-xxd240jg\\faiss_cpu.egg-info\n",
      "      writing C:\\Users\\SAGAR\\AppData\\Local\\Temp\\pip-pip-egg-info-xxd240jg\\faiss_cpu.egg-info\\PKG-INFO\n",
      "      writing dependency_links to C:\\Users\\SAGAR\\AppData\\Local\\Temp\\pip-pip-egg-info-xxd240jg\\faiss_cpu.egg-info\\dependency_links.txt\n",
      "      writing top-level names to C:\\Users\\SAGAR\\AppData\\Local\\Temp\\pip-pip-egg-info-xxd240jg\\faiss_cpu.egg-info\\top_level.txt\n",
      "      writing manifest file 'C:\\Users\\SAGAR\\AppData\\Local\\Temp\\pip-pip-egg-info-xxd240jg\\faiss_cpu.egg-info\\SOURCES.txt'\n",
      "      error: package directory 'C:\\Users\\SAGAR\\AppData\\Local\\Temp\\pip-install-woxxe6yx\\faiss-gpu_0feda222e4b6467ab5b8c6f1d4b247d9\\faiss\\faiss\\python' does not exist\n",
      "      [end of output]\n",
      "  \n",
      "  note: This error originates from a subprocess, and is likely not a problem with pip.\n",
      "error: metadata-generation-failed\n",
      "\n",
      "× Encountered error while generating package metadata.\n",
      "╰─> See above for output.\n",
      "\n",
      "note: This is an issue with the package mentioned above, not pip.\n",
      "hint: See above for details.\n"
     ]
    }
   ],
   "source": [
    "pip install faiss-gpu"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "import faiss"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Collecting sentence-transformersNote: you may need to restart the kernel to use updated packages.\n",
      "\n",
      "  Downloading sentence-transformers-2.2.2.tar.gz (85 kB)\n",
      "     -------------------------------------- 86.0/86.0 kB 404.9 kB/s eta 0:00:00\n",
      "  Preparing metadata (setup.py): started\n",
      "  Preparing metadata (setup.py): still running...\n",
      "  Preparing metadata (setup.py): finished with status 'done'\n",
      "Collecting transformers<5.0.0,>=4.6.0\n",
      "  Downloading transformers-4.28.1-py3-none-any.whl (7.0 MB)\n",
      "     ---------------------------------------- 7.0/7.0 MB 262.7 kB/s eta 0:00:00\n",
      "Requirement already satisfied: tqdm in d:\\ai-youtube\\ai-youtube-search\\env\\lib\\site-packages (from sentence-transformers) (4.65.0)\n",
      "Requirement already satisfied: torch>=1.6.0 in d:\\ai-youtube\\ai-youtube-search\\env\\lib\\site-packages (from sentence-transformers) (2.0.0)\n",
      "Collecting torchvision\n",
      "  Downloading torchvision-0.15.1-cp38-cp38-win_amd64.whl (1.2 MB)\n",
      "     ---------------------------------------- 1.2/1.2 MB 195.0 kB/s eta 0:00:00\n",
      "Requirement already satisfied: numpy in d:\\ai-youtube\\ai-youtube-search\\env\\lib\\site-packages (from sentence-transformers) (1.23.5)\n",
      "Collecting scikit-learn\n",
      "  Downloading scikit_learn-1.2.2-cp38-cp38-win_amd64.whl (8.3 MB)\n",
      "     ---------------------------------------- 8.3/8.3 MB 295.7 kB/s eta 0:00:00\n",
      "Collecting scipy\n",
      "  Downloading scipy-1.10.1-cp38-cp38-win_amd64.whl (42.2 MB)\n",
      "     -------------------------------------- 42.2/42.2 MB 233.2 kB/s eta 0:00:00\n",
      "Collecting nltk\n",
      "  Downloading nltk-3.8.1-py3-none-any.whl (1.5 MB)\n",
      "     ---------------------------------------- 1.5/1.5 MB 457.3 kB/s eta 0:00:00\n",
      "Collecting sentencepiece\n",
      "  Downloading sentencepiece-0.1.98-cp38-cp38-win_amd64.whl (977 kB)\n",
      "     ------------------------------------ 977.9/977.9 kB 469.3 kB/s eta 0:00:00\n",
      "Collecting huggingface-hub>=0.4.0\n",
      "  Downloading huggingface_hub-0.13.4-py3-none-any.whl (200 kB)\n",
      "     ------------------------------------ 200.1/200.1 kB 320.2 kB/s eta 0:00:00\n",
      "Requirement already satisfied: filelock in d:\\ai-youtube\\ai-youtube-search\\env\\lib\\site-packages (from huggingface-hub>=0.4.0->sentence-transformers) (3.10.7)\n",
      "Requirement already satisfied: packaging>=20.9 in d:\\ai-youtube\\ai-youtube-search\\env\\lib\\site-packages (from huggingface-hub>=0.4.0->sentence-transformers) (23.1)\n",
      "Requirement already satisfied: requests in d:\\ai-youtube\\ai-youtube-search\\env\\lib\\site-packages (from huggingface-hub>=0.4.0->sentence-transformers) (2.28.2)\n",
      "Collecting pyyaml>=5.1\n",
      "  Downloading PyYAML-6.0-cp38-cp38-win_amd64.whl (155 kB)\n",
      "     ------------------------------------ 155.4/155.4 kB 273.4 kB/s eta 0:00:00\n",
      "Requirement already satisfied: typing-extensions>=3.7.4.3 in d:\\ai-youtube\\ai-youtube-search\\env\\lib\\site-packages (from huggingface-hub>=0.4.0->sentence-transformers) (4.5.0)\n",
      "Requirement already satisfied: sympy in d:\\ai-youtube\\ai-youtube-search\\env\\lib\\site-packages (from torch>=1.6.0->sentence-transformers) (1.11.1)\n",
      "Requirement already satisfied: jinja2 in d:\\ai-youtube\\ai-youtube-search\\env\\lib\\site-packages (from torch>=1.6.0->sentence-transformers) (3.1.2)\n",
      "Requirement already satisfied: networkx in d:\\ai-youtube\\ai-youtube-search\\env\\lib\\site-packages (from torch>=1.6.0->sentence-transformers) (3.0)\n",
      "Requirement already satisfied: colorama in d:\\ai-youtube\\ai-youtube-search\\env\\lib\\site-packages (from tqdm->sentence-transformers) (0.4.6)\n",
      "Collecting tokenizers!=0.11.3,<0.14,>=0.11.1\n",
      "  Downloading tokenizers-0.13.3-cp38-cp38-win_amd64.whl (3.5 MB)\n",
      "     ---------------------------------------- 3.5/3.5 MB 272.0 kB/s eta 0:00:00\n",
      "Requirement already satisfied: regex!=2019.12.17 in d:\\ai-youtube\\ai-youtube-search\\env\\lib\\site-packages (from transformers<5.0.0,>=4.6.0->sentence-transformers) (2023.3.23)\n",
      "Collecting joblib\n",
      "  Downloading joblib-1.2.0-py3-none-any.whl (297 kB)\n",
      "     ------------------------------------ 298.0/298.0 kB 919.3 kB/s eta 0:00:00\n",
      "Collecting click\n",
      "  Using cached click-8.1.3-py3-none-any.whl (96 kB)\n",
      "Collecting threadpoolctl>=2.0.0\n",
      "  Using cached threadpoolctl-3.1.0-py3-none-any.whl (14 kB)\n",
      "Collecting pillow!=8.3.*,>=5.3.0\n",
      "  Downloading Pillow-9.5.0-cp38-cp38-win_amd64.whl (2.5 MB)\n",
      "     ---------------------------------------- 2.5/2.5 MB 371.9 kB/s eta 0:00:00\n",
      "Requirement already satisfied: MarkupSafe>=2.0 in d:\\ai-youtube\\ai-youtube-search\\env\\lib\\site-packages (from jinja2->torch>=1.6.0->sentence-transformers) (2.1.2)\n",
      "Requirement already satisfied: certifi>=2017.4.17 in d:\\ai-youtube\\ai-youtube-search\\env\\lib\\site-packages (from requests->huggingface-hub>=0.4.0->sentence-transformers) (2022.12.7)\n",
      "Requirement already satisfied: idna<4,>=2.5 in d:\\ai-youtube\\ai-youtube-search\\env\\lib\\site-packages (from requests->huggingface-hub>=0.4.0->sentence-transformers) (3.4)\n",
      "Requirement already satisfied: charset-normalizer<4,>=2 in d:\\ai-youtube\\ai-youtube-search\\env\\lib\\site-packages (from requests->huggingface-hub>=0.4.0->sentence-transformers) (3.1.0)\n",
      "Requirement already satisfied: urllib3<1.27,>=1.21.1 in d:\\ai-youtube\\ai-youtube-search\\env\\lib\\site-packages (from requests->huggingface-hub>=0.4.0->sentence-transformers) (1.26.15)\n",
      "Requirement already satisfied: mpmath>=0.19 in d:\\ai-youtube\\ai-youtube-search\\env\\lib\\site-packages (from sympy->torch>=1.6.0->sentence-transformers) (1.3.0)\n",
      "Building wheels for collected packages: sentence-transformers\n",
      "  Building wheel for sentence-transformers (setup.py): started\n",
      "  Building wheel for sentence-transformers (setup.py): finished with status 'done'\n",
      "  Created wheel for sentence-transformers: filename=sentence_transformers-2.2.2-py3-none-any.whl size=125960 sha256=f437ed918f23059192c21f93c6d03d8760bda2bc3744db1a93f593114f8ccf0a\n",
      "  Stored in directory: c:\\users\\sagar\\appdata\\local\\pip\\cache\\wheels\\5e\\6f\\8c\\d88aec621f3f542d26fac0342bef5e693335d125f4e54aeffe\n",
      "Successfully built sentence-transformers\n",
      "Installing collected packages: tokenizers, sentencepiece, threadpoolctl, scipy, pyyaml, pillow, joblib, click, scikit-learn, nltk, huggingface-hub, transformers, torchvision, sentence-transformers\n",
      "Successfully installed click-8.1.3 huggingface-hub-0.13.4 joblib-1.2.0 nltk-3.8.1 pillow-9.5.0 pyyaml-6.0 scikit-learn-1.2.2 scipy-1.10.1 sentence-transformers-2.2.2 sentencepiece-0.1.98 threadpoolctl-3.1.0 tokenizers-0.13.3 torchvision-0.15.1 transformers-4.28.1\n"
     ]
    }
   ],
   "source": [
    "pip install -U sentence-transformers"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "d:\\AI-youtube\\ai-youtube-search\\env\\lib\\site-packages\\tqdm\\auto.py:21: TqdmWarning: IProgress not found. Please update jupyter and ipywidgets. See https://ipywidgets.readthedocs.io/en/stable/user_install.html\n",
      "  from .autonotebook import tqdm as notebook_tqdm\n",
      "Downloading (…)e9125/.gitattributes: 100%|██████████| 1.18k/1.18k [00:00<00:00, 295kB/s]\n",
      "Downloading (…)_Pooling/config.json: 100%|██████████| 190/190 [00:00<00:00, 13.4kB/s]\n",
      "Downloading (…)7e55de9125/README.md: 100%|██████████| 10.6k/10.6k [00:00<00:00, 626kB/s]\n",
      "Downloading (…)55de9125/config.json: 100%|██████████| 612/612 [00:00<00:00, 43.9kB/s]\n",
      "Downloading (…)ce_transformers.json: 100%|██████████| 116/116 [00:00<00:00, 9.44kB/s]\n",
      "Downloading (…)125/data_config.json: 100%|██████████| 39.3k/39.3k [00:00<00:00, 2.56MB/s]\n",
      "Downloading pytorch_model.bin: 100%|██████████| 90.9M/90.9M [00:20<00:00, 4.46MB/s]\n",
      "Downloading (…)nce_bert_config.json: 100%|██████████| 53.0/53.0 [00:00<00:00, 13.3kB/s]\n",
      "Downloading (…)cial_tokens_map.json: 100%|██████████| 112/112 [00:00<00:00, 18.7kB/s]\n",
      "Downloading (…)e9125/tokenizer.json: 100%|██████████| 466k/466k [00:00<00:00, 3.61MB/s]\n",
      "Downloading (…)okenizer_config.json: 100%|██████████| 350/350 [00:00<00:00, 70.3kB/s]\n",
      "Downloading (…)9125/train_script.py: 100%|██████████| 13.2k/13.2k [00:00<00:00, 1.02MB/s]\n",
      "Downloading (…)7e55de9125/vocab.txt: 100%|██████████| 232k/232k [00:00<00:00, 3.94MB/s]\n",
      "Downloading (…)5de9125/modules.json: 100%|██████████| 349/349 [00:00<00:00, 43.7kB/s]\n"
     ]
    }
   ],
   "source": [
    "from sentence_transformers import SentenceTransformer\n",
    "sentences = df['text']\n",
    "\n",
    "model = SentenceTransformer('sentence-transformers/all-MiniLM-L6-v2')\n",
    "embeddings = model.encode(sentences)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[-0.04345131, -0.04586752, -0.05298122, ..., -0.0742354 ,\n",
       "        -0.09265208,  0.01695291],\n",
       "       [ 0.047466  , -0.08408324,  0.01368688, ..., -0.02863744,\n",
       "        -0.03696448,  0.03885221],\n",
       "       [-0.01699636,  0.00947554,  0.05835804, ..., -0.12459251,\n",
       "         0.04001966,  0.02312284],\n",
       "       ...,\n",
       "       [ 0.03386167, -0.00088098, -0.00587285, ..., -0.05599724,\n",
       "        -0.05819496, -0.04510283],\n",
       "       [ 0.06096314, -0.02810737, -0.09345506, ...,  0.03849424,\n",
       "        -0.133299  , -0.03642083],\n",
       "       [-0.01607218, -0.03708102, -0.00288862, ..., -0.08570195,\n",
       "        -0.12126768, -0.00983806]], dtype=float32)"
      ]
     },
     "execution_count": 48,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "embeddings"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(32, 384)"
      ]
     },
     "execution_count": 47,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "embeddings.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "384"
      ]
     },
     "execution_count": 43,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "d=embeddings.shape[1]\n",
    "d"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "index=faiss.IndexFlatL2(d)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "index.is_trained"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "index.add(embeddings)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "32"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "index.ntotal"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "xq=model.encode(['what is bootstrap'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[ 5 13  7  6 12]]\n",
      "[[0.9068463 1.0041317 1.0270896 1.0398413 1.1198778]]\n"
     ]
    }
   ],
   "source": [
    "D, I = index.search(xq,5)\n",
    "print(I)\n",
    "print(D)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "lines=df['text']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[\"5:  To create a bootstrap dataset that is the same size as the original, we just randomly select samples from the original dataset. The important detail is that we're allowed to pick the same sample more than once. This is the first sample that we randomly select.\",\n",
       " \"13:  Using a bootstrap sample and considering only a subset of variables at each step results in a wide variety of trees. The variety is what makes random forests more effective than individual decision trees. Sweet. Now that we've created a random forest, how do we use it?\",\n",
       " \"7:  So here it is in the bootstrap dataset. Lastly, here's the fourth randomly selected sample. Note, it's the same as the third. And here it is.\",\n",
       " \"6:  So it's the first sample in our bootstrap dataset. This is the second randomly selected sample from the original dataset. So it's the second sample in our bootstrap dataset. Here's the third randomly selected sample.\",\n",
       " '12:  Now, go back to step one and repeat. Make a new bootstrap dataset and build a tree considering a subset of variables at each step. Ideally, you do this hundreds of times, but we only have space to show six. But you get the idea.']"
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "[f'{i}: {lines[i]}' for i in I[0]]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [],
   "source": [
    "nlist=10\n",
    "quantizer=faiss.IndexFlatL2(d)\n",
    "index=faiss.IndexIVFFlat(quantizer,d,nlist)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "False"
      ]
     },
     "execution_count": 37,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "index.is_trained"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [],
   "source": [
    "index.train(embeddings)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [],
   "source": [
    "index.add(embeddings)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "32"
      ]
     },
     "execution_count": 40,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "index.ntotal"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[ 5 13 12 11  4]]\n",
      "CPU times: total: 0 ns\n",
      "Wall time: 3 ms\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "D, I =index.search(xq,5)\n",
    "print(I)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[\"5:  To create a bootstrap dataset that is the same size as the original, we just randomly select samples from the original dataset. The important detail is that we're allowed to pick the same sample more than once. This is the first sample that we randomly select.\",\n",
       " \"13:  Using a bootstrap sample and considering only a subset of variables at each step results in a wide variety of trees. The variety is what makes random forests more effective than individual decision trees. Sweet. Now that we've created a random forest, how do we use it?\",\n",
       " '12:  Now, go back to step one and repeat. Make a new bootstrap dataset and build a tree considering a subset of variables at each step. Ideally, you do this hundreds of times, but we only have space to show six. But you get the idea.',\n",
       " \"11:  And we just build the tree as usual, but only considering a random subset of variables at each step. Double bound. We built a tree, one, using a bootstrap dataset, and two, only considering a random subset of variables at each step. Here's the tree we just made.\",\n",
       " \"4:  Step one, create a bootstrap dataset. Imagine that these four samples are the entire dataset that we are going to build a tree from. I know it's crazy small, but just pretend for now.\"]"
      ]
     },
     "execution_count": 42,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "[f'{i}: {lines[i]}' for i in I[0]]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {},
   "outputs": [],
   "source": [
    "m=8\n",
    "bits=5\n",
    "\n",
    "quantizer=faiss.IndexFlatL2(d)\n",
    "index=faiss.IndexIVFPQ(quantizer,d,16,m,bits)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "False"
      ]
     },
     "execution_count": 50,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "index.is_trained"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {},
   "outputs": [],
   "source": [
    "index.train(embeddings)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "metadata": {},
   "outputs": [],
   "source": [
    "index.add(embeddings)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[ 5  7 12 -1 -1]]\n",
      "CPU times: total: 31.2 ms\n",
      "Wall time: 1.26 s\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "D, I =index.search(xq,5)\n",
    "print(I)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.16"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
