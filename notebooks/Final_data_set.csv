title,start,end,text,duration
"StatQuest: Random Forests Part 1 - Building, Using and Evaluating",0.0,23.04," Wandering around, around them, forest, I won't get lost because of stat quest. Hello, I'm Josh Starmer and welcome to stat quest. Today we're going to be starting part one of a series on random forests, and we're going to talk about building and evaluating random forests.",23.04
"StatQuest: Random Forests Part 1 - Building, Using and Evaluating",23.04,41.72," Note, random forests are built from decision trees, so if you don't already know about those, check out my stat quest and be-fuck. Decision trees are easy to build, easy to use, and easy to interpret. But in practice, they are not that awesome.",18.68
"StatQuest: Random Forests Part 1 - Building, Using and Evaluating",41.72,61.36," To quote from the elements of statistical learning, aka the Bible of Machine Learning, trees have one aspect that prevents them from being the ideal tool for predictive learning, namely in accuracy. In other words, they work great with the data used to create them, but they are not flexible",19.64
"StatQuest: Random Forests Part 1 - Building, Using and Evaluating",61.36,77.72, when it comes to classifying new samples. The good news is that random forests combine the simplicity of decision trees with flexibility resulting in a vast improvement in accuracy. So let's make a random forest.,16.36
"StatQuest: Random Forests Part 1 - Building, Using and Evaluating",77.72,91.76," Step one, create a bootstrap dataset. Imagine that these four samples are the entire dataset that we are going to build a tree from. I know it's crazy small, but just pretend for now.",14.040000000000006
"StatQuest: Random Forests Part 1 - Building, Using and Evaluating",91.76,109.76," To create a bootstrap dataset that is the same size as the original, we just randomly select samples from the original dataset. The important detail is that we're allowed to pick the same sample more than once. This is the first sample that we randomly select.",18.0
"StatQuest: Random Forests Part 1 - Building, Using and Evaluating",109.76,126.4, So it's the first sample in our bootstrap dataset. This is the second randomly selected sample from the original dataset. So it's the second sample in our bootstrap dataset. Here's the third randomly selected sample.,16.64
"StatQuest: Random Forests Part 1 - Building, Using and Evaluating",126.4,138.84," So here it is in the bootstrap dataset. Lastly, here's the fourth randomly selected sample. Note, it's the same as the third. And here it is.",12.439999999999998
"StatQuest: Random Forests Part 1 - Building, Using and Evaluating",138.84,162.36," Bam, we've created a bootstrap dataset. Step two for creating a random forest is to create a decision tree using the bootstrap dataset, but only use a random subset of variables or columns at each step. In this example, we will only consider two variables or columns at each step.",23.52000000000001
"StatQuest: Random Forests Part 1 - Building, Using and Evaluating",162.4,188.12," Note, we'll talk more about how to determine the optimal number of variables to consider later. Thus, instead of considering all four variables to figure out how to split the root node, we randomly select two. In this case, we randomly selected good blood circulation and blocked arteries as candidates for the root node.",25.72
"StatQuest: Random Forests Part 1 - Building, Using and Evaluating",188.2,216.84," Just for the sake of the example, assume that good blood circulation did the best job separating the samples. Since we used good blood circulation, I'm going to gray it out so that we focus on the remaining variables. Now we need to figure out how to split samples at this node. Just like for the root, we randomly select two variables as candidates instead of all three remaining columns.",28.640000000000015
"StatQuest: Random Forests Part 1 - Building, Using and Evaluating",216.84,240.76," And we just build the tree as usual, but only considering a random subset of variables at each step. Double bound. We built a tree, one, using a bootstrap dataset, and two, only considering a random subset of variables at each step. Here's the tree we just made.",23.919999999999987
"StatQuest: Random Forests Part 1 - Building, Using and Evaluating",240.84,258.88," Now, go back to step one and repeat. Make a new bootstrap dataset and build a tree considering a subset of variables at each step. Ideally, you do this hundreds of times, but we only have space to show six. But you get the idea.",18.039999999999992
"StatQuest: Random Forests Part 1 - Building, Using and Evaluating",258.88,280.2," Using a bootstrap sample and considering only a subset of variables at each step results in a wide variety of trees. The variety is what makes random forests more effective than individual decision trees. Sweet. Now that we've created a random forest, how do we use it?",21.319999999999993
"StatQuest: Random Forests Part 1 - Building, Using and Evaluating",280.2,296.52," Well, first we get a new patient. We've got all the measurements. And now we want to know if they have heart disease or not. So we take the data and run it down the first tree that we made.",16.319999999999993
"StatQuest: Random Forests Part 1 - Building, Using and Evaluating",296.6,313.84," Boobedoo,onym, ar, ba,doo, tim rebo, the first tree says yes. The patient has heart disease and we keep track of that here. Now we run the data down the second tree that we made.",17.239999999999952
"StatQuest: Random Forests Part 1 - Building, Using and Evaluating",313.84,332.26," And we keep track of that. For all the trees we made. After running the data down all of the trees in the random forest, we see which option received more votes.",18.420000000000016
"StatQuest: Random Forests Part 1 - Building, Using and Evaluating",332.26,346.26," In this case, yes received the most votes, so we will conclude that this patient has heart disease. Bam! Oh no, terminology alert.",14.0
"StatQuest: Random Forests Part 1 - Building, Using and Evaluating",346.26,363.98," Boots strapping the data, plus using the aggregate to make a decision, is called bagging. Okay, now we've seen how to create and use a random forest. How do we know if it's any good?",17.720000000000027
"StatQuest: Random Forests Part 1 - Building, Using and Evaluating",363.98,384.86," Remember when we created the Boots strapped data set? We allowed duplicate entries in the Boots strapped data set. As a result, this entry was not included in the Boots strapped data set. Typically, about one-third of the original data does not end up in the Boots strapped data",20.879999999999995
"StatQuest: Random Forests Part 1 - Building, Using and Evaluating",384.86,399.18," set. Here's the entry that didn't end up in the Boots strapped data set. Just. If the original data set were larger, we'd have more than just one entry over here.",14.319999999999993
"StatQuest: Random Forests Part 1 - Building, Using and Evaluating",399.18,414.38000000000005," This is called the Out of Bag Data Set. If it were up to me, I would have named it the Out of Boot Data Set, since it's the entries that didn't make it into the Boots strapped data set. Unfortunately, it's not up to me.",15.200000000000045
"StatQuest: Random Forests Part 1 - Building, Using and Evaluating",414.38000000000005,436.54," Since the Out of Bag Data was not used to create this tree, we can run it through and see if it correctly classifies the sample as no heart disease. In this case, the tree correctly labels the Out of Bag sample, no. Then we run this Out of Bag sample through all of the other trees that were built without",22.159999999999968
"StatQuest: Random Forests Part 1 - Building, Using and Evaluating",436.54,453.94," it. This tree incorrectly labeled the Out of Bag sample, yes. These trees correctly labeled the Out of Bag sample, no. Since the label with the most votes wins, it is the label that we assign this Out of Bag",17.399999999999977
"StatQuest: Random Forests Part 1 - Building, Using and Evaluating",453.94,473.74," sample. In this case, the Out of Bag sample is correctly labeled by the random forest. We then do the same thing for all of the Out of Bag samples for all of the trees. This Out of Bag sample was also correctly labeled.",19.80000000000001
"StatQuest: Random Forests Part 1 - Building, Using and Evaluating",473.74,481.86, This Out of Bag sample was incorrectly labeled. Etc. Etc. Etc.,8.120000000000005
"StatQuest: Random Forests Part 1 - Building, Using and Evaluating",481.86,501.54," Ultimately, we can measure how accurate our random forest is by the proportion of Out of Bag samples that were correctly classified by the random forest. The proportion of Out of Bag samples that were incorrectly classified is the Out of Bag error.",19.680000000000007
"StatQuest: Random Forests Part 1 - Building, Using and Evaluating",501.54,522.98," OK. We now know how to 1 build a random forest, 2 use a random forest, and 3 estimate the accuracy of a random forest. However, now that we know how to do this, we can talk a little more about how to do this.",21.439999999999998
"StatQuest: Random Forests Part 1 - Building, Using and Evaluating",522.98,544.3," Remember when we built our first tree and we only use 2 variables, columns of data, to make a decision at each step. Now we can compare the Out of Bag error for a random forest built using only 2 variables per step, to a random forest built using 3 variables per step.",21.319999999999936
"StatQuest: Random Forests Part 1 - Building, Using and Evaluating",544.3399999999999,564.5799999999999," We test a bunch of different settings and choose the most accurate random forest. In other words, 1 we build a random forest, and then 2 we estimate the accuracy of a random forest. Then we change the number of variables used per step, and we do this a bunch of times and",20.24000000000001
"StatQuest: Random Forests Part 1 - Building, Using and Evaluating",564.5799999999999,581.02," then choose the one that is the most accurate. Typically, we start by using the square of the number of variables, and then try a few settings above and below that value. Triple BAM",16.440000000000055
"StatQuest: Random Forests Part 1 - Building, Using and Evaluating",581.02,593.34," Hooray, we've made it to the end of another exciting stat quest. Tune in next week and we'll talk about how to deal with missing data and how to cluster the samples. All right, until then, quest on.",12.32000000000005
